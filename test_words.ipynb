{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import string\n",
    "import math\n",
    "import re\n",
    "\n",
    "from pprint import pprint\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import nltk.help\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag, ne_chunk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic=\"sports\"\n",
    "thresh = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dd():\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with open(topic+\"_author_articles.pkl\", 'r') as auth_ar_in:\n",
    "#    auth_ar = pickle.load(auth_ar_in)\n",
    "with open(topic+\"_auth_sents.pkl\", 'r') as ins:\n",
    "    sents = pickle.load(ins)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "# JJ adjective RB adverb\n",
    "#nltk.help.upenn_tagset()\n",
    "teststr = u\"hello\"\n",
    "if re.match(r'[\\w-]+$', teststr):\n",
    "    print teststr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nadverbs = set([])\\nfor author, sentences in sents.iteritems():\\n    for s in sentences:\\n        s = s.lower()\\n        words = word_tokenize(s)\\n        tagged_words = pos_tag(words)\\n        #if re.match(r\\'[\\\\w-]+$\\', teststr):\\n        adverbs = adverbs | set([word for word,pos in tagged_words if pos == \\'RB\\' \\n                                 and re.match(r\\'[\\\\w-]+$\\', word) \\n                                 and word[-2:] == \"ly\"])\\n        #if len(adjectives) > 0:   print adjectives\\n    #adverbs = set(adverbs)\\n    \\nprint adverbs'"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "adverbs = set([])\n",
    "for author, sentences in sents.iteritems():\n",
    "    for s in sentences:\n",
    "        s = s.lower()\n",
    "        words = word_tokenize(s)\n",
    "        tagged_words = pos_tag(words)\n",
    "        #if re.match(r'[\\w-]+$', teststr):\n",
    "        adverbs = adverbs | set([word for word,pos in tagged_words if pos == 'RB' \n",
    "                                 and re.match(r'[\\w-]+$', word) \n",
    "                                 and word[-2:] == \"ly\"])\n",
    "        #if len(adjectives) > 0:   print adjectives\n",
    "    #adverbs = set(adverbs)\n",
    "    \n",
    "print adverbs'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp = string.punctuation\n",
    "sp = unicode(sp)\n",
    "punct = [s for s in sp]\n",
    "\n",
    "#punct = [u'!', u'$', u'%', u'?', u':', u';', u'``', u\"''\", u'\\u2013']\n",
    "punct.append(u'``')\n",
    "punct.append(u\"''\")\n",
    "punct.append(u'\\u2013')\n",
    "\n",
    "'''[(u'!', 0), (u'\"', 0), (u'#', 0), (u'$', 0), (u'%', 0), (u'&', 0), \n",
    "    (u\"'\", 0), (u\"''\", 1), (u'(', 0), (u')', 0), (u'*', 0), (u'+', 0), \n",
    "    (u',', 1), (u'-', 0), (u'.', 1), (u'/', 0), (u':', 0), (u';', 0), \n",
    "    (u'<', 0), (u'=', 0), (u'>', 0), (u'?', 0), (u'@', 0), (u'[', 0), \n",
    "    (u'\\\\', 0), (u']', 0), (u'^', 0), (u'_', 0), (u'`', 0), (u'``', 1), \n",
    "    (u'{', 0), (u'|', 0), (u'}', 0), (u'~', 0), (u'\\u2013', 0)]'''\n",
    "\n",
    "#print punct, len(punct)\n",
    "swords = stopwords.words('english')\n",
    "swords.append('\\'s')\n",
    "swords.append('\\'t')\n",
    "#print swords\n",
    "\n",
    "#advswords = set(swords) | adverbs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#advswords = sorted(list(advswords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129\n",
      "282\n"
     ]
    }
   ],
   "source": [
    "print len(swords)\n",
    "print len(adverbs) #politics 501, all 1059\n",
    "#print len(advswords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print advswords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_features():\n",
    "    all_punct_counts = dict.fromkeys(punct, 0)\n",
    "    #all_advsword_counts = dict.fromkeys(advswords, 0)\n",
    "    all_sword_counts = dict.fromkeys(swords, 0)\n",
    "    #all_adverb_counts = dict.fromkeys(adverbs, 0)\n",
    "    for author, sentences in sents.iteritems():\n",
    "        for s in sentences:\n",
    "            s = s.replace(u\"\\u2018\", \"'\").replace(u\"\\u2019\", \"'\") \\\n",
    "                .replace(u\"\\u201c\",'\"').replace(u\"\\u201d\", '\"') \\\n",
    "                .replace(u\"\\u030F\", '\"').replace(u\"''\", '\"')\n",
    "            words = word_tokenize(s) #punctuation is included as words\n",
    "            for word in words:\n",
    "                word = word.lower()\n",
    "                #print word, [word]               \n",
    "                if word in punct:# or word[0] in punct:\n",
    "                    all_punct_counts[word] += 1\n",
    "                else:\n",
    "                    #if word in advswords:\n",
    "                    #    all_advsword_counts[word] += 1\n",
    "                    if word in swords:\n",
    "                        all_sword_counts[word] += 1\n",
    "                    #if word in adverbs:\n",
    "                    #    all_adverb_counts[word] += 1\n",
    "                        \n",
    "    all_punct_list = sorted(all_punct_counts.items(), key=lambda x: x[1])\n",
    "    #all_advsword_list = sorted(all_advsword_counts.items(), key=lambda x: x[1])\n",
    "    all_sword_list = sorted(all_sword_counts.items(), key=lambda x: x[1])\n",
    "    #all_adverb_list = sorted(all_adverb_counts.items(), key=lambda x: x[1])\n",
    "    return all_punct_list, all_sword_list#, all_adverb_list, all_advsword_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_punct_list, all_sword_list = preprocess_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'\"', 0), (u'*', 0), (u'/', 0), (u'<', 0), (u'>', 0)] 35\n",
      "[(u'yourselves', 0), (u'ours', 0), (u't', 0), (u'hers', 0), (u'theirs', 0)] 129\n"
     ]
    }
   ],
   "source": [
    "print all_punct_list[:5], len(all_punct_list)\n",
    "#print all_advsword_list[:5], len(all_advsword_list)\n",
    "print all_sword_list[:5], len(all_sword_list)\n",
    "#print all_adverb_list[:5], len(all_adverb_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "small_punct_list = [(apl, count) for apl, count in all_punct_list if count > thresh]\n",
    "#small_advsword_list = [(aal, count) for aal, count in all_advsword_list if count > thresh]\n",
    "small_sword_list = [(asl, count) for asl, count in all_sword_list if count > thresh]\n",
    "#small_adverb_list = [(aavl, count) for aavl, count in all_adverb_list if count > thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'&', 9), (u'%', 19), (u'-', 45), (u'$', 55), (u'[', 62)]\n",
      "18\n",
      "[(u':', 423), (u\"''\", 642), (u'``', 699), (u'.', 3666), (u',', 3672)]\n",
      "[(u'&', 9), (u'%', 19), (u'-', 45), (u'$', 55), (u'[', 62), (u']', 62), (u'!', 63), (u';', 88), (u\"'\", 152), (u'?', 177), (u'(', 185), (u'\\u2013', 256), (u')', 382), (u':', 423), (u\"''\", 642), (u'``', 699), (u'.', 3666), (u',', 3672)]\n",
      "[(u'!', 63), (u'$', 55), (u'%', 19), (u'&', 9), (u\"'\", 152), (u\"''\", 642), (u'(', 185), (u')', 382), (u',', 3672), (u'-', 45), (u'.', 3666), (u':', 423), (u';', 88), (u'?', 177), (u'[', 62), (u']', 62), (u'``', 699), (u'\\u2013', 256)]\n"
     ]
    }
   ],
   "source": [
    "pprint(small_punct_list[:5])\n",
    "print len(small_punct_list)\n",
    "pprint(small_punct_list[-5:])\n",
    "print small_punct_list\n",
    "print sorted(small_punct_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print small_advsword_list[:5]\n",
    "#print len(small_advsword_list)\n",
    "#print small_advsword_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'ourselves', 7), (u'whom', 7), (u'further', 9), (u'above', 10), (u'am', 13)]\n",
      "115\n",
      "[(u'and', 1688), (u'of', 1786), (u'to', 1805), (u'a', 1964), (u'the', 4908)]\n"
     ]
    }
   ],
   "source": [
    "print small_sword_list[:5]\n",
    "print len(small_sword_list)\n",
    "print small_sword_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print small_adverb_list[:5]\n",
    "#print len(small_adverb_list)\n",
    "#print small_adverb_list[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'&', u'%', u'-', u'$', u'[', u']', u'!', u';', u\"'\", u'?', u'(', u'\\u2013', u')', u':', u\"''\", u'``', u'.', u',']\n",
      "[u'ourselves', u'whom', u'further', u'above', u'am', u'itself', u'themselves', u'himself', u'doing', u'both', u'once', u'why', u'until', u'having', u'too', u'such', u'under', u'between', u'again', u'each', u'does', u'few', u'own', u'during', u'same', u'her', u'these', u'any', u'being', u'through', u'she', u'off', u'very', u'should', u'other', u'those', u'while', u'where', u'how', u'because', u'here', u'down', u'your', u'me', u'most', u'then', u'against', u'him', u'its', u'our', u'before', u'can', u'than', u'only', u'now', u'them', u'my', u'no', u'over', u'which', u'some', u'into', u'after', u'about', u'did', u'just', u'what', u'will', u'been', u'more', u'if', u'so', u'up', u'when', u'or', u'do', u'out', u'has', u'all', u'who', u'there', u'their', u'are', u'an', u'not', u'by', u'had', u'have', u'from', u'were', u'this', u'but', u'you', u'be', u'his', u'they', u'at', u'as', u'we', u'he', u'is', u'with', u'i', u'on', u'for', u'it', u'was', u'that', \"'s\", u'in', u'and', u'of', u'to', u'a', u'the']\n"
     ]
    }
   ],
   "source": [
    "small_puncts = list(zip(*small_punct_list)[0])\n",
    "print small_puncts\n",
    "#small_advswords = list(zip(*small_advsword_list)[0])\n",
    "#print small_advswords\n",
    "small_swords = list(zip(*small_sword_list)[0])\n",
    "print small_swords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_frequencies(len_w, counts, subset=False, log=True):\n",
    "    '''takes number tokens as float,list of (k, v), and converts v from int count to frequency.\n",
    "    If subset, takes frequency over the counts rather than the whole\n",
    "    set of tokens'''\n",
    "    freqs = []\n",
    "    sorted_counts = zip(*sorted(counts.items()))[1]\n",
    "\n",
    "    countsum = float(sum(sorted_counts))\n",
    "    for sc in sorted_counts:\n",
    "        if subset:\n",
    "            if countsum > 0.0:\n",
    "                freqs.append(sc/countsum)\n",
    "            else:\n",
    "                freqs.append(0.0)\n",
    "        else:\n",
    "            fs = sc/len_w\n",
    "            if log:\n",
    "                if fs > 0.0:\n",
    "                    f = abs(math.log(fs)) #log of fs will always be negative, and mnb can't handle that\n",
    "                    freqs.append(f)\n",
    "                else:\n",
    "                    freqs.append(0.0)\n",
    "            else:\n",
    "                freqs.append(fs)\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joe Gorman\n",
      "DJ Gallo\n",
      "Russell Jackson\n",
      "Graham Parker\n",
      "Michael Lewis\n",
      "Les Carpenter\n",
      "Guardian sport\n",
      "[('len_s', 24), ('len_w', 4.208333333333333), (u'!', 0), (u'$', 0), (u'%', 0), (u'&', 0), (u\"'\", 0), (u\"''\", 0), (u'(', 0), (u')', 0), (u',', 0), (u'-', 0), (u'.', 1), (u':', 0), (u';', 0), (u'?', 0), (u'[', 0), (u']', 0), (u'``', 0), (u'\\u2013', 0), (\"'s\", 1), (u'a', 2), (u'about', 0), (u'above', 0), (u'after', 0), (u'again', 0), (u'against', 0), (u'all', 0), (u'am', 1), (u'an', 0), (u'and', 0), (u'any', 0), (u'are', 0), (u'as', 0), (u'at', 1), (u'be', 0), (u'because', 0), (u'been', 0), (u'before', 0), (u'being', 0), (u'between', 0), (u'both', 0), (u'but', 0), (u'by', 0), (u'can', 0), (u'did', 0), (u'do', 0), (u'does', 0), (u'doing', 0), (u'down', 0), (u'during', 0), (u'each', 0), (u'few', 0), (u'for', 0), (u'from', 0), (u'further', 0), (u'had', 0), (u'has', 0), (u'have', 0), (u'having', 0), (u'he', 0), (u'her', 0), (u'here', 0), (u'him', 0), (u'himself', 0), (u'his', 0), (u'how', 0), (u'i', 1), (u'if', 0), (u'in', 1), (u'into', 0), (u'is', 0), (u'it', 0), (u'its', 0), (u'itself', 0), (u'just', 0), (u'me', 0), (u'more', 0), (u'most', 0), (u'my', 1), (u'no', 0), (u'not', 0), (u'now', 0), (u'of', 1), (u'off', 0), (u'on', 0), (u'once', 0), (u'only', 0), (u'or', 0), (u'other', 0), (u'our', 0), (u'ourselves', 0), (u'out', 0), (u'over', 0), (u'own', 0), (u'same', 0), (u'she', 0), (u'should', 0), (u'so', 0), (u'some', 0), (u'such', 0), (u'than', 0), (u'that', 0), (u'the', 0), (u'their', 0), (u'them', 0), (u'themselves', 0), (u'then', 0), (u'there', 0), (u'these', 0), (u'they', 0), (u'this', 0), (u'those', 0), (u'through', 0), (u'to', 1), (u'too', 0), (u'under', 0), (u'until', 0), (u'up', 0), (u'very', 0), (u'was', 0), (u'we', 0), (u'were', 0), (u'what', 0), (u'when', 0), (u'where', 0), (u'which', 0), (u'while', 0), (u'who', 0), (u'whom', 0), (u'why', 0), (u'will', 0), (u'with', 1), (u'you', 0), (u'your', 0)]\n",
      "[24, 4.208333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.61512051684126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.61512051684126, 3.9219733362813143, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.61512051684126, 0.0, 0.0, 0.0, 0.0, 0.0, 4.61512051684126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.61512051684126, 0.0, 4.61512051684126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.61512051684126, 0.0, 0.0, 0.0, 4.61512051684126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.61512051684126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 4.61512051684126, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "featuresli = []\n",
    "#authors = []\n",
    "raw_features = []\n",
    "\n",
    "def pd():\n",
    "    return 0\n",
    "#label = 1\n",
    "#labels = []\n",
    "for author, sentences in sents.iteritems():\n",
    "    print author\n",
    "    \n",
    "    for s in sentences:\n",
    "        #punct_counts = defaultdict(pd)\n",
    "        punct_counts = dict.fromkeys(small_puncts, 0)\n",
    "        #advsword_counts = dict.fromkeys(small_advswords, 0)\n",
    "        sword_counts = dict.fromkeys(small_swords, 0)\n",
    "        features = []\n",
    "        len_w = 0.0\n",
    "        count_w = 0.0\n",
    "        s = s.replace(u\"\\u2018\", \"'\").replace(u\"\\u2019\", \"'\") \\\n",
    "            .replace(u\"\\u201c\",'\"').replace(u\"\\u201d\", '\"') \\\n",
    "            .replace(u\"\\u030F\", '\"').replace(u\"''\", '\"')\n",
    "        words = word_tokenize(s) #punctuation is included as words\n",
    "        #print s, \"\\n\", [s]\n",
    "        #print len(words)\n",
    "        for word in words:\n",
    "            word = word.lower()\n",
    "            #print word, [word]               \n",
    "            if word in small_puncts:# or word[0] in punct:\n",
    "                punct_counts[word] += 1\n",
    "            elif word in small_swords:\n",
    "                sword_counts[word] += 1\n",
    "            len_w += len(word)\n",
    "            count_w += 1\n",
    "        avg_wlen = len_w/count_w\n",
    "        #print avg_wlen\n",
    "        punct_freq = get_frequencies(len_w, punct_counts)#zip(*sorted(punct_counts.items()))[1]\n",
    "        sword_freq = get_frequencies(len_w, sword_counts)#zip(*sorted(sword_counts.items()))[1]\n",
    "        #print punct_freq\n",
    "        #print sword_freq\n",
    "        #print sorted(punct_counts.items())\n",
    "        features.append(len(words)) #total number of tokens in sentence\n",
    "        features.append(avg_wlen) #average word/token length\n",
    "        features += punct_freq #frequency of punctuation tokens\n",
    "        features += sword_freq #frequency of stopword tokens\n",
    "        rf = [('len_s', len(words)), ('len_w', avg_wlen)]\n",
    "        rf += sorted(punct_counts.items()) + sorted(sword_counts.items())\n",
    "        #print rf\n",
    "        featuresli.append(features)\n",
    "        #authors.append(label)\n",
    "        raw_features.append(rf)\n",
    "    #labels.append((label, author))\n",
    "    #label += 1\n",
    "\n",
    "#print labels\n",
    "print raw_features[0]\n",
    "print featuresli[0]\n",
    "#print authors\n",
    "#print featuresli\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['len_s', 'len_w', u'!', u'$', u'%', u'&', u\"'\", u\"''\", u'(', u')', u',', u'-', u'.', u':', u';', u'?', u'[', u']', u'``', u'\\u2013', \"'s\", u'a', u'about', u'above', u'after', u'again', u'against', u'all', u'am', u'an', u'and', u'any', u'are', u'as', u'at', u'be', u'because', u'been', u'before', u'being', u'between', u'both', u'but', u'by', u'can', u'did', u'do', u'does', u'doing', u'down', u'during', u'each', u'few', u'for', u'from', u'further', u'had', u'has', u'have', u'having', u'he', u'her', u'here', u'him', u'himself', u'his', u'how', u'i', u'if', u'in', u'into', u'is', u'it', u'its', u'itself', u'just', u'me', u'more', u'most', u'my', u'no', u'not', u'now', u'of', u'off', u'on', u'once', u'only', u'or', u'other', u'our', u'ourselves', u'out', u'over', u'own', u'same', u'she', u'should', u'so', u'some', u'such', u'than', u'that', u'the', u'their', u'them', u'themselves', u'then', u'there', u'these', u'they', u'this', u'those', u'through', u'to', u'too', u'under', u'until', u'up', u'very', u'was', u'we', u'were', u'what', u'when', u'where', u'which', u'while', u'who', u'whom', u'why', u'will', u'with', u'you', u'your']\n"
     ]
    }
   ],
   "source": [
    "feature_words_adv = ['len_s', 'len_w'] + list(zip(*sorted(small_punct_list))[0]) \\\n",
    "                      + list(zip(*sorted(small_sword_list))[0])\n",
    "print feature_words_adv\n",
    "#zip(*sorted(counts.items()))[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(topic+\"_features_small.pkl\", 'w') as outs:\n",
    "    pickle.dump(featuresli, outs)\n",
    "with open(topic+\"_feature_words_small.pkl\", 'w') as fwouts:\n",
    "    pickle.dump(feature_words_adv, fwouts)\n",
    "with open(topic+\"_raw_features_small.pkl\", 'w') as rfouts:\n",
    "    pickle.dump(raw_features, rfouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
